{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "339fc675",
   "metadata": {},
   "source": [
    "# SKLearn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3594742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6cefaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028e00ce",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e50f38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 1.],\n",
       "       [0., 1., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 1., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binarization\n",
    "# preprocessing technique used to convert numerical value into boolean values.\n",
    "arr = np.array([[2.1, -1.9, 5.5],[-1.5, 2.4, 3.5],[0.5, -7.9, 5.6],[5.9, 2.3, -5.8]])\n",
    "# threshold is 0.5 all values above 0.5 will become 1 otherwise 0\n",
    "data_binarized = preprocessing.Binarizer(threshold=0.5).transform(arr)\n",
    "data_binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca48497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_removed = [1.11022302e-16 0.00000000e+00 0.00000000e+00]\n",
      "Stddeviation_removed = [1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Mean removal\n",
    "# eliminate the so that every feature centre on zero\n",
    "data_scaled = preprocessing.scale(arr)\n",
    "print(\"Mean_removed =\", data_scaled.mean(axis=0))\n",
    "print(\"Stddeviation_removed =\", data_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54a5ae47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Min max scaled data:\n",
      " [[0.48648649 0.58252427 0.99122807]\n",
      " [0.         1.         0.81578947]\n",
      " [0.27027027 0.         1.        ]\n",
      " [1.         0.99029126 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# scaling\n",
    "# data should not be large or small in magnitude\n",
    "# minmaxscalar preserve the original shape of data\n",
    "data_scaler_minmax = preprocessing.MinMaxScaler(feature_range=(0,1)) # minmaxscalar transform each feature into given range\n",
    "data_scaled_minmax = data_scaler_minmax.fit_transform(arr)\n",
    "print (\"Min max scaled data:\\n\", data_scaled_minmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ec9b8d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 normalized data:\n",
      " [[ 0.22105263 -0.2         0.57894737]\n",
      " [-0.2027027   0.32432432  0.47297297]\n",
      " [ 0.03571429 -0.56428571  0.4       ]\n",
      " [ 0.42142857  0.16428571 -0.41428571]]\n"
     ]
    }
   ],
   "source": [
    "# Normalization\n",
    "# use to modify feature vector\n",
    "# normalization is necesasry so that feature vectors can be measured at common scale.\n",
    "# 2 types of normalization\n",
    "# L1 normalization is also called least absolute deviation\n",
    "# L1 is calculated in such a way that sum of absolute value always remains upto 1 in each row\n",
    "data_normalized_l1 = preprocessing.normalize(arr, norm='l1')\n",
    "print(\"L1 normalized data:\\n\", data_normalized_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3be0890a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2 normalized data:\n",
      " [[ 0.33946114 -0.30713151  0.88906489]\n",
      " [-0.33325106  0.53320169  0.7775858 ]\n",
      " [ 0.05156558 -0.81473612  0.57753446]\n",
      " [ 0.68706914  0.26784051 -0.6754239 ]]\n"
     ]
    }
   ],
   "source": [
    "# L2 normalization\n",
    "# L2 also called least square method\n",
    "# it is calculated such that sum of squares remains upto 1\n",
    "data_normalized_l2 = preprocessing.normalize(arr, norm='l2')\n",
    "print(\"L2 normalized data:\\n\", data_normalized_l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd5f032",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8c0a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43bc6287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = sns.load_dataset('iris')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e2f0be8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.drop(['species'], axis = 1)\n",
    "y = dataset['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f584a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "405ee649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d607c8a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a3f0c06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cfbf99f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59386158",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1ca86d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "# used for classification and regression. task is to find best decision boundry. the best decision boundry is called as hyperplane.\n",
    "# and extreme cases called as support vectors.\n",
    "# used for image classification, text classification\n",
    "# 2 types : 1. linear : means data can be seperate using one straight line. 2. non-linear SVM : data can not seperate usign one straight line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a645cca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "st_x= StandardScaler()    \n",
    "x_train= st_x.fit_transform(x_train)    \n",
    "x_test= st_x.transform(x_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "810e7154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC # \"Support vector classifier\"  \n",
    "classifier = SVC(kernel='linear', random_state=0)  \n",
    "classifier.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "10a05fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= classifier.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1c8dee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix  \n",
    "cm= confusion_matrix(y_test, y_pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bb342503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0,  0],\n",
       "       [ 0, 17,  1],\n",
       "       [ 0,  0, 11]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ecfb845c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7fd7e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB\n",
    "# supervised learning algorithm. it is probabilistic classifier. \n",
    "# 3 types of NB model. guassianNB, bernoullliNB, multinominalNB.\n",
    "# Steps to implement:\n",
    "# Data Pre-processing step\n",
    "# Fitting Naive Bayes to the Training set\n",
    "# Predicting the test result\n",
    "# Test accuracy of the result(Creation of Confusion matrix)\n",
    "# Visualizing the test set result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e1458d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "sc = StandardScaler()  \n",
    "x_train = sc.fit_transform(x_train)  \n",
    "x_test = sc.transform(x_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e16c1411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Naive Bayes to the Training set  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "classifier = GaussianNB()  \n",
    "classifier.fit(x_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0c74c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results  \n",
    "y_pred = classifier.predict(x_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6cf71b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3948cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "# attribute selection measures : gini index and information gain\n",
    "# steps : Data Pre-processing step\n",
    "# Fitting a Decision-Tree algorithm to the Training set\n",
    "# Predicting the test result\n",
    "# Test accuracy of the result(Creation of Confusion matrix)\n",
    "# Visualizing the test set result.\n",
    "#feature Scaling  \n",
    "from sklearn.preprocessing import StandardScaler    \n",
    "st_x= StandardScaler()  \n",
    "x_train= st_x.fit_transform(x_train)    \n",
    "x_test= st_x.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24c28561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Decision Tree classifier to the training set  \n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "classifier= DecisionTreeClassifier(criterion='entropy', random_state=0)  \n",
    "classifier.fit(x_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4d752595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the test set result  \n",
    "y_pred= classifier.predict(x_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b62bba06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finding accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1e352d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c4f25bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict test set result\n",
    "y_pred = classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd1ddf48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8d8b9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# creating a RF classifier\n",
    "clf = RandomForestClassifier(n_estimators = 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55149656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model on the training dataset\n",
    "# fit function is used to train the model using the training sets as parameters\n",
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9442991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing predictions on the test dataset\n",
    "y_pred = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e67dc668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
